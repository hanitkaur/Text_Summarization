{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ob6Jc07nKjZ"
      },
      "source": [
        "##Extraction-Based Summarizer Scraped Wikipedia articles using Beautiful Soup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L80gVJiZ1fvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b61604-71e2-4150-a0e7-657b81ff0525"
      },
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "#persian cuisine\n",
        "scraped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Iranian_cuisine')\n",
        "article = scraped_data.read()\n",
        "\n",
        "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
        "\n",
        "paragraphs = parsed_article.find_all('p')\n",
        "\n",
        "article_text = \"\"\n",
        "\n",
        "for p in paragraphs:\n",
        "    article_text += p.text"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_4EmP8l1tLi"
      },
      "source": [
        "# Removing Square Brackets and Extra Spaces\n",
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
        "#any whitespace character \\s+\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-AKwDkc15h6"
      },
      "source": [
        "# Removing special characters and digits\n",
        "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
        "#any whitespace character \\s+\n",
        "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3dlAgyRvLa4"
      },
      "source": [
        "##Convert paragraphs to sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1BxJpQx15ss"
      },
      "source": [
        "sentence_list = nltk.sent_tokenize(article_text)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGWRc5NY2g8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38c66a2-2c5c-4e91-a70e-60519443fa81"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ-LlCwBwE7J"
      },
      "source": [
        "###Loop to calculate the word frequencies. <br>Tokenize the sentences<br>if word is not a stopword and is in the word list, the count is added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA4mWOgK2X6Y"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(formatted_article_text):\n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4v06sl2xA_v"
      },
      "source": [
        "## Keys() method<br>The keys() method returns a view object. The view object contains the keys of the dictionary, as a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u70SSN1cxO2i",
        "outputId": "de05acfe-3e15-496a-eba6-def0d18c83cd"
      },
      "source": [
        "shoe = {\n",
        "  \"brand\": \"Nike\",\n",
        "  \"series\": \"Air Max\",\n",
        "  \"price\": 100\n",
        "}\n",
        "\n",
        "var = shoe.keys()\n",
        "\n",
        "print(var)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['brand', 'series', 'price'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOPnTZ9ixUvl"
      },
      "source": [
        "###When an item is added in the dictionary, the view object also gets updated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5rYePFbxSd0",
        "outputId": "d9a108fd-def6-436f-9f1b-3b6a0d72e6de"
      },
      "source": [
        "shoe[\"color\"] = \"red\"\n",
        "\n",
        "print(var)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['brand', 'series', 'price', 'color'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzSatUTS8WK7"
      },
      "source": [
        "##Find weighted frequency of occurence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D34gqm-42lBq"
      },
      "source": [
        "maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw5PmlZHycfs",
        "outputId": "6d2ca52f-fb11-4f8f-d435-0fd6c0c96540"
      },
      "source": [
        "shoe = {\n",
        "  \"brand\": \"Nike\",\n",
        "  \"series\": \"Air Max\",\n",
        "  \"price\": 100\n",
        "}\n",
        "\n",
        "var = shoe.values()\n",
        "\n",
        "print(var)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values(['Nike', 'Air Max', 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2LMj2pa8L0k"
      },
      "source": [
        "###Replace words with weighted frequency in sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNUVxbcD2lOD"
      },
      "source": [
        "sentence_scores = {}\n",
        "for sent in sentence_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0mMnhCX8lLJ"
      },
      "source": [
        "###Heap queue <br>heap queue algorithm, also known as the priority queue algorithm<br>It makes it possible to view the data (words/scores) -  our heap, as a regular Python list<br>heapq.nlargest(n, iterable, key=None)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThhA39562rxN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "e9f65336-7a0e-405b-d102-174396fa488a"
      },
      "source": [
        "import heapq\n",
        "summary_sentences = heapq.nlargest(5, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "summary = ' '.join(summary_sentences)\n",
        "summary"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Typical Iranian cuisine includes a wide variety of dishes, including several forms of kebab, stew, soup, and pilaf dishes, as well as various salads, desserts, pastries, and drinks. Apart from dishes of rice with kebab or stew, there are various rice-based Iranian dishes cooked in the traditional methods of polow and dami. It is followed by six chapters on the preparation of various dishes: four on rice dishes, one on qalya, and one on ƒÅsh. Baluchi cuisine also includes several date-based dishes, as well as various types of bread. Rose water, a flavored water made by steeping rose petals in water, is also a traditional and common ingredient in many Iranian dishes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jFFhIsUzSjSR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}